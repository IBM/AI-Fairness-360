{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of Reweighting pre-processing, Adversarial Debiasing in-processing and Reject Option Classification (ROC) post-processing algorithms for bias mitigation.\n",
    "- The debiasing function used is implemented in the `RejectOptionClassification` class.\n",
    "- Divide the dataset into training, validation, and testing partitions.\n",
    "- Train classifier on original training data.\n",
    "- Estimate the optimal classification threshold, that maximizes balanced accuracy without fairness constraints.\n",
    "- Estimate the optimal classification threshold, and the critical region boundary (ROC margin) using a validation set for the desired constraint on fairness. The best parameters are those that maximize the classification threshold while satisfying the fairness constraints.\n",
    "- The constraints can be used on the following fairness measures:\n",
    "    * Statistical parity difference on the predictions of the classifier\n",
    "    * Average odds difference for the classifier\n",
    "    * Equal opportunity difference for the classifier\n",
    "- Determine the prediction scores for testing data. Using the estimated optimal classification threshold, compute accuracy and fairness metrics.\n",
    "- Using the determined optimal classification threshold and the ROC margin, adjust the predictions. Report accuracy and fairness metric on the new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import interactive, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"adult\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#     dataset_orig = AdultDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['race'])\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "#     dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['age'])\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 0}]\n",
    "        unprivileged_groups = [{'sex': 1}]\n",
    "        dataset_orig = load_preproc_data_compas(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]  \n",
    "        dataset_orig = load_preproc_data_compas(['race'])\n",
    "\n",
    "        \n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.1\n",
    "metric_lb = -0.1\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up training data and display properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing: Reweighing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.190698\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Weights:\")\n",
    "print(dataset_orig_train.instance_weights)\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(dataset_orig_train)\n",
    "dataset_transf_train = RW.transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[1.09009788 1.09009788 0.85643005 ... 0.85643005 0.85643005 2.1573167 ]\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Weights:\")\n",
    "print(dataset_transf_train.instance_weights)\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-processing: Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session() \n",
    "plain_model_nodebias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:133: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:137: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:82: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:87: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:155: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:157: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:161: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\guill\\documents\\carrera\\elp\\aif360\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:182: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.749527\n",
      "epoch 0; iter: 200; batch classifier loss: 0.395791\n",
      "epoch 1; iter: 0; batch classifier loss: 0.451405\n",
      "epoch 1; iter: 200; batch classifier loss: 0.489790\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466488\n",
      "epoch 2; iter: 200; batch classifier loss: 0.440943\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398345\n",
      "epoch 3; iter: 200; batch classifier loss: 0.459410\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550487\n",
      "epoch 4; iter: 200; batch classifier loss: 0.394380\n",
      "epoch 5; iter: 0; batch classifier loss: 0.443929\n",
      "epoch 5; iter: 200; batch classifier loss: 0.398449\n",
      "epoch 6; iter: 0; batch classifier loss: 0.455488\n",
      "epoch 6; iter: 200; batch classifier loss: 0.390759\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456536\n",
      "epoch 7; iter: 200; batch classifier loss: 0.385938\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421836\n",
      "epoch 8; iter: 200; batch classifier loss: 0.362498\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347076\n",
      "epoch 9; iter: 200; batch classifier loss: 0.376837\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471728\n",
      "epoch 10; iter: 200; batch classifier loss: 0.372091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409732\n",
      "epoch 11; iter: 200; batch classifier loss: 0.393182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334858\n",
      "epoch 12; iter: 200; batch classifier loss: 0.397584\n",
      "epoch 13; iter: 0; batch classifier loss: 0.414980\n",
      "epoch 13; iter: 200; batch classifier loss: 0.379579\n",
      "epoch 14; iter: 0; batch classifier loss: 0.364410\n",
      "epoch 14; iter: 200; batch classifier loss: 0.334514\n",
      "epoch 15; iter: 0; batch classifier loss: 0.444838\n",
      "epoch 15; iter: 200; batch classifier loss: 0.469136\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481180\n",
      "epoch 16; iter: 200; batch classifier loss: 0.469745\n",
      "epoch 17; iter: 0; batch classifier loss: 0.388632\n",
      "epoch 17; iter: 200; batch classifier loss: 0.480241\n",
      "epoch 18; iter: 0; batch classifier loss: 0.392621\n",
      "epoch 18; iter: 200; batch classifier loss: 0.484113\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459635\n",
      "epoch 19; iter: 200; batch classifier loss: 0.442216\n",
      "epoch 20; iter: 0; batch classifier loss: 0.420808\n",
      "epoch 20; iter: 200; batch classifier loss: 0.429856\n",
      "epoch 21; iter: 0; batch classifier loss: 0.435877\n",
      "epoch 21; iter: 200; batch classifier loss: 0.374273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474497\n",
      "epoch 22; iter: 200; batch classifier loss: 0.492182\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400915\n",
      "epoch 23; iter: 200; batch classifier loss: 0.380410\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501588\n",
      "epoch 24; iter: 200; batch classifier loss: 0.388425\n",
      "epoch 25; iter: 0; batch classifier loss: 0.383839\n",
      "epoch 25; iter: 200; batch classifier loss: 0.433158\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476198\n",
      "epoch 26; iter: 200; batch classifier loss: 0.458251\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405110\n",
      "epoch 27; iter: 200; batch classifier loss: 0.369394\n",
      "epoch 28; iter: 0; batch classifier loss: 0.398716\n",
      "epoch 28; iter: 200; batch classifier loss: 0.409800\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386575\n",
      "epoch 29; iter: 200; batch classifier loss: 0.314864\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459949\n",
      "epoch 30; iter: 200; batch classifier loss: 0.411592\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387346\n",
      "epoch 31; iter: 200; batch classifier loss: 0.385477\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439889\n",
      "epoch 32; iter: 200; batch classifier loss: 0.393498\n",
      "epoch 33; iter: 0; batch classifier loss: 0.394994\n",
      "epoch 33; iter: 200; batch classifier loss: 0.361547\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425894\n",
      "epoch 34; iter: 200; batch classifier loss: 0.422941\n",
      "epoch 35; iter: 0; batch classifier loss: 0.336961\n",
      "epoch 35; iter: 200; batch classifier loss: 0.468460\n",
      "epoch 36; iter: 0; batch classifier loss: 0.380486\n",
      "epoch 36; iter: 200; batch classifier loss: 0.365835\n",
      "epoch 37; iter: 0; batch classifier loss: 0.396060\n",
      "epoch 37; iter: 200; batch classifier loss: 0.493241\n",
      "epoch 38; iter: 0; batch classifier loss: 0.356131\n",
      "epoch 38; iter: 200; batch classifier loss: 0.454454\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466513\n",
      "epoch 39; iter: 200; batch classifier loss: 0.506909\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396416\n",
      "epoch 40; iter: 200; batch classifier loss: 0.375274\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440774\n",
      "epoch 41; iter: 200; batch classifier loss: 0.443818\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451713\n",
      "epoch 42; iter: 200; batch classifier loss: 0.398364\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403346\n",
      "epoch 43; iter: 200; batch classifier loss: 0.448672\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437848\n",
      "epoch 44; iter: 200; batch classifier loss: 0.485168\n",
      "epoch 45; iter: 0; batch classifier loss: 0.324800\n",
      "epoch 45; iter: 200; batch classifier loss: 0.456406\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457606\n",
      "epoch 46; iter: 200; batch classifier loss: 0.341736\n",
      "epoch 47; iter: 0; batch classifier loss: 0.352165\n",
      "epoch 47; iter: 200; batch classifier loss: 0.434755\n",
      "epoch 48; iter: 0; batch classifier loss: 0.351223\n",
      "epoch 48; iter: 200; batch classifier loss: 0.552728\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445136\n",
      "epoch 49; iter: 200; batch classifier loss: 0.347390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x1dd0cccc0c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_nodebias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model_nodebias.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model_nodebias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.207083\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.206143\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.804422\n",
      "Test set: Balanced classification accuracy = 0.656253\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.443989\n",
      "Test set: Average odds difference = -0.273663\n",
      "Test set: Theil_index = 0.178989\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "sess = tf.Session()\n",
    "plain_model_debias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=True,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.684884; batch adversarial loss: 0.621481\n",
      "epoch 0; iter: 200; batch classifier loss: 0.444297; batch adversarial loss: 0.652825\n",
      "epoch 1; iter: 0; batch classifier loss: 0.517512; batch adversarial loss: 0.676000\n",
      "epoch 1; iter: 200; batch classifier loss: 0.549574; batch adversarial loss: 0.667661\n",
      "epoch 2; iter: 0; batch classifier loss: 0.465986; batch adversarial loss: 0.653992\n",
      "epoch 2; iter: 200; batch classifier loss: 0.441834; batch adversarial loss: 0.620508\n",
      "epoch 3; iter: 0; batch classifier loss: 0.493553; batch adversarial loss: 0.629533\n",
      "epoch 3; iter: 200; batch classifier loss: 0.419524; batch adversarial loss: 0.600496\n",
      "epoch 4; iter: 0; batch classifier loss: 0.460217; batch adversarial loss: 0.676073\n",
      "epoch 4; iter: 200; batch classifier loss: 0.384316; batch adversarial loss: 0.593867\n",
      "epoch 5; iter: 0; batch classifier loss: 0.410312; batch adversarial loss: 0.624691\n",
      "epoch 5; iter: 200; batch classifier loss: 0.390113; batch adversarial loss: 0.677111\n",
      "epoch 6; iter: 0; batch classifier loss: 0.453243; batch adversarial loss: 0.618272\n",
      "epoch 6; iter: 200; batch classifier loss: 0.399196; batch adversarial loss: 0.595515\n",
      "epoch 7; iter: 0; batch classifier loss: 0.419143; batch adversarial loss: 0.625105\n",
      "epoch 7; iter: 200; batch classifier loss: 0.422543; batch adversarial loss: 0.571307\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400503; batch adversarial loss: 0.581540\n",
      "epoch 8; iter: 200; batch classifier loss: 0.450222; batch adversarial loss: 0.616580\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435346; batch adversarial loss: 0.610084\n",
      "epoch 9; iter: 200; batch classifier loss: 0.405274; batch adversarial loss: 0.637873\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438331; batch adversarial loss: 0.559024\n",
      "epoch 10; iter: 200; batch classifier loss: 0.423177; batch adversarial loss: 0.604682\n",
      "epoch 11; iter: 0; batch classifier loss: 0.431628; batch adversarial loss: 0.605359\n",
      "epoch 11; iter: 200; batch classifier loss: 0.422262; batch adversarial loss: 0.588759\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402394; batch adversarial loss: 0.597127\n",
      "epoch 12; iter: 200; batch classifier loss: 0.486324; batch adversarial loss: 0.647002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383728; batch adversarial loss: 0.595291\n",
      "epoch 13; iter: 200; batch classifier loss: 0.453419; batch adversarial loss: 0.593716\n",
      "epoch 14; iter: 0; batch classifier loss: 0.353631; batch adversarial loss: 0.605567\n",
      "epoch 14; iter: 200; batch classifier loss: 0.356766; batch adversarial loss: 0.617004\n",
      "epoch 15; iter: 0; batch classifier loss: 0.404236; batch adversarial loss: 0.580541\n",
      "epoch 15; iter: 200; batch classifier loss: 0.555819; batch adversarial loss: 0.550000\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521433; batch adversarial loss: 0.572181\n",
      "epoch 16; iter: 200; batch classifier loss: 0.403857; batch adversarial loss: 0.589546\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491586; batch adversarial loss: 0.578286\n",
      "epoch 17; iter: 200; batch classifier loss: 0.374958; batch adversarial loss: 0.568432\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454799; batch adversarial loss: 0.556891\n",
      "epoch 18; iter: 200; batch classifier loss: 0.441095; batch adversarial loss: 0.563546\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456202; batch adversarial loss: 0.639210\n",
      "epoch 19; iter: 200; batch classifier loss: 0.396170; batch adversarial loss: 0.524156\n",
      "epoch 20; iter: 0; batch classifier loss: 0.386882; batch adversarial loss: 0.605652\n",
      "epoch 20; iter: 200; batch classifier loss: 0.462036; batch adversarial loss: 0.604859\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439717; batch adversarial loss: 0.588325\n",
      "epoch 21; iter: 200; batch classifier loss: 0.417446; batch adversarial loss: 0.565869\n",
      "epoch 22; iter: 0; batch classifier loss: 0.384357; batch adversarial loss: 0.589369\n",
      "epoch 22; iter: 200; batch classifier loss: 0.395016; batch adversarial loss: 0.642451\n",
      "epoch 23; iter: 0; batch classifier loss: 0.353124; batch adversarial loss: 0.654855\n",
      "epoch 23; iter: 200; batch classifier loss: 0.411513; batch adversarial loss: 0.663547\n",
      "epoch 24; iter: 0; batch classifier loss: 0.382716; batch adversarial loss: 0.646037\n",
      "epoch 24; iter: 200; batch classifier loss: 0.312602; batch adversarial loss: 0.596701\n",
      "epoch 25; iter: 0; batch classifier loss: 0.351599; batch adversarial loss: 0.608990\n",
      "epoch 25; iter: 200; batch classifier loss: 0.435286; batch adversarial loss: 0.647520\n",
      "epoch 26; iter: 0; batch classifier loss: 0.415433; batch adversarial loss: 0.585315\n",
      "epoch 26; iter: 200; batch classifier loss: 0.445579; batch adversarial loss: 0.670455\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425224; batch adversarial loss: 0.611027\n",
      "epoch 27; iter: 200; batch classifier loss: 0.432489; batch adversarial loss: 0.638245\n",
      "epoch 28; iter: 0; batch classifier loss: 0.399009; batch adversarial loss: 0.616341\n",
      "epoch 28; iter: 200; batch classifier loss: 0.489413; batch adversarial loss: 0.571505\n",
      "epoch 29; iter: 0; batch classifier loss: 0.404497; batch adversarial loss: 0.566837\n",
      "epoch 29; iter: 200; batch classifier loss: 0.457276; batch adversarial loss: 0.656965\n",
      "epoch 30; iter: 0; batch classifier loss: 0.377847; batch adversarial loss: 0.598703\n",
      "epoch 30; iter: 200; batch classifier loss: 0.430835; batch adversarial loss: 0.674860\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409643; batch adversarial loss: 0.581545\n",
      "epoch 31; iter: 200; batch classifier loss: 0.436385; batch adversarial loss: 0.573821\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452068; batch adversarial loss: 0.603368\n",
      "epoch 32; iter: 200; batch classifier loss: 0.587878; batch adversarial loss: 0.632376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457905; batch adversarial loss: 0.631296\n",
      "epoch 33; iter: 200; batch classifier loss: 0.512175; batch adversarial loss: 0.588433\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404490; batch adversarial loss: 0.607872\n",
      "epoch 34; iter: 200; batch classifier loss: 0.414734; batch adversarial loss: 0.599596\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447019; batch adversarial loss: 0.584674\n",
      "epoch 35; iter: 200; batch classifier loss: 0.385752; batch adversarial loss: 0.581707\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473091; batch adversarial loss: 0.535692\n",
      "epoch 36; iter: 200; batch classifier loss: 0.558580; batch adversarial loss: 0.594216\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416156; batch adversarial loss: 0.581375\n",
      "epoch 37; iter: 200; batch classifier loss: 0.544989; batch adversarial loss: 0.618579\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464148; batch adversarial loss: 0.519140\n",
      "epoch 38; iter: 200; batch classifier loss: 0.375944; batch adversarial loss: 0.651339\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433507; batch adversarial loss: 0.608023\n",
      "epoch 39; iter: 200; batch classifier loss: 0.398000; batch adversarial loss: 0.576394\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477288; batch adversarial loss: 0.547687\n",
      "epoch 40; iter: 200; batch classifier loss: 0.330333; batch adversarial loss: 0.622644\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402073; batch adversarial loss: 0.566567\n",
      "epoch 41; iter: 200; batch classifier loss: 0.415269; batch adversarial loss: 0.633068\n",
      "epoch 42; iter: 0; batch classifier loss: 0.376245; batch adversarial loss: 0.647539\n",
      "epoch 42; iter: 200; batch classifier loss: 0.317407; batch adversarial loss: 0.626956\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390787; batch adversarial loss: 0.607602\n",
      "epoch 43; iter: 200; batch classifier loss: 0.400199; batch adversarial loss: 0.628270\n",
      "epoch 44; iter: 0; batch classifier loss: 0.531903; batch adversarial loss: 0.599517\n",
      "epoch 44; iter: 200; batch classifier loss: 0.462443; batch adversarial loss: 0.605577\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385822; batch adversarial loss: 0.636831\n",
      "epoch 45; iter: 200; batch classifier loss: 0.390474; batch adversarial loss: 0.631112\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419088; batch adversarial loss: 0.591164\n",
      "epoch 46; iter: 200; batch classifier loss: 0.496641; batch adversarial loss: 0.575792\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411446; batch adversarial loss: 0.666841\n",
      "epoch 47; iter: 200; batch classifier loss: 0.449930; batch adversarial loss: 0.601750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.423809; batch adversarial loss: 0.590944\n",
      "epoch 48; iter: 200; batch classifier loss: 0.443803; batch adversarial loss: 0.558847\n",
      "epoch 49; iter: 0; batch classifier loss: 0.574912; batch adversarial loss: 0.652849\n",
      "epoch 49; iter: 200; batch classifier loss: 0.347987; batch adversarial loss: 0.587090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x1dd10ec9588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_debias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = plain_model_debias.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = plain_model_debias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.087973\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.093916\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.792139\n",
      "Test set: Balanced classification accuracy = 0.668719\n",
      "Test set: Disparate impact = 0.549817\n",
      "Test set: Equal opportunity difference = -0.100694\n",
      "Test set: Average odds difference = -0.059413\n",
      "Test set: Theil_index = 0.170749\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "#metric_test_bef = compute_metrics(dataset_orig_test, dataset_nodebiasing_test, \n",
    "#                unprivileged_groups, privileged_groups)\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: Reject Option Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression classifier and predictions\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
    "y_valid = dataset_orig_valid_pred.labels\n",
    "dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "fav_inds = dataset_orig_valid_pred.scores > 0.5\n",
    "dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "y_test = dataset_orig_test_pred.labels\n",
    "dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "fav_inds = dataset_orig_test_pred.scores > 0.5\n",
    "dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.806742\n",
      "Balanced accuracy = 0.6626\n",
      "Statistical parity difference = -0.2125\n",
      "Disparate impact = 0.0000\n",
      "Average odds difference = -0.2829\n",
      "Equal opportunity difference = -0.4604\n",
      "Theil index = 0.1754\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_orig_test_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy())\n",
    "\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(dataset_orig_valid,dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.1684\n",
      "Optimal ROC margin = 0.0790\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions from Test Set with ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.676129\n",
      "Balanced accuracy = 0.7180\n",
      "Statistical parity difference = -0.0905\n",
      "Disparate impact = 0.8173\n",
      "Average odds difference = -0.0267\n",
      "Equal opportunity difference = -0.0551\n",
      "Theil index = 0.1061\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_test = ROC.predict(dataset_orig_test_pred)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_transf_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy()) \n",
    "\n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "F. Kamiran, and T. Claders,\"Data preprocessing techniques for classification without discrimination\",\n",
    "Knowledge and Information Systems, 33(1):1–33, 2012. \n",
    "\n",
    "B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning\",\n",
    "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.\n",
    "\n",
    "F. Kamiran, A. Karim, and X. Zhang,  \"Decision theory for discrimination-aware classification\",\n",
    "In IEEE International Conference on Data Mining, pp. 924–929, 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
