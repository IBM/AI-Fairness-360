{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of Reweighing pre-processing, Adversarial Debiasing in-processing and Reject Option Classification (ROC) post-processing algorithms for bias mitigation.\n",
    "- Load imports\n",
    "- Dataset\n",
    "    * Load Adult, COMPAS, or German dataset and set privileged and unprivileged groups\n",
    "    * Divide the dataset into training, validation, and testing partitions\n",
    "    * Show dataset properties\n",
    "- Pre-processing: Reweighing.\n",
    "    * Show difference in mean outcomes for original training data\n",
    "    * Assign weights with reweighing\n",
    "    * Show difference in mean outcomes for transformed training data\n",
    "- In-processing: Adversarial Debiasing.\n",
    "    * Train model without debiasing, predict, and show metrics\n",
    "    * Train model with debiasing, predict, and show metrics\n",
    "- Post-processing: Reject Option Classification (ROC).\n",
    "    * Show metrics for test set from Adversarial Debiasing without debiasing\n",
    "    * Fit ROC model\n",
    "    * Transform labels and show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from warnings import warn \n",
    "\n",
    "# Avoid deprecation warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import interactive, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#     dataset_orig = AdultDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['race'])\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "#     dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['age'])\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 0}]\n",
    "        unprivileged_groups = [{'sex': 1}]\n",
    "        dataset_orig = load_preproc_data_compas(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]  \n",
    "        dataset_orig = load_preproc_data_compas(['race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up training data and display properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing: Reweighing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights = 1.000000 , 1.000000, 1.000000, ...\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.100117\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Weights = %f , %f, %f, ...\" % (dataset_orig_train.instance_weights[1], dataset_orig_train.instance_weights[2], \\\n",
    "                                    dataset_orig_train.instance_weights[3]))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(dataset_orig_train)\n",
    "dataset_transf_train = RW.transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for reweighted training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights = 0.822259 , 0.955174, 0.955174, ...\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Weights = %8f , %8f, %8f, ...\" % (dataset_transf_train.instance_weights[1], dataset_transf_train.instance_weights[2], \\\n",
    "                                    dataset_transf_train.instance_weights[3]))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-processing: Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session() \n",
    "plain_model_nodebias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.668088\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631008\n",
      "epoch 2; iter: 0; batch classifier loss: 0.659046\n",
      "epoch 3; iter: 0; batch classifier loss: 0.502799\n",
      "epoch 4; iter: 0; batch classifier loss: 0.608407\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612942\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578477\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527597\n",
      "epoch 8; iter: 0; batch classifier loss: 0.620062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.550934\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584196\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.628668\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492051\n",
      "epoch 14; iter: 0; batch classifier loss: 0.624512\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573710\n",
      "epoch 16; iter: 0; batch classifier loss: 0.559718\n",
      "epoch 17; iter: 0; batch classifier loss: 0.605144\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540690\n",
      "epoch 19; iter: 0; batch classifier loss: 0.615361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528360\n",
      "epoch 21; iter: 0; batch classifier loss: 0.665857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.559647\n",
      "epoch 23; iter: 0; batch classifier loss: 0.645617\n",
      "epoch 24; iter: 0; batch classifier loss: 0.563636\n",
      "epoch 25; iter: 0; batch classifier loss: 0.574281\n",
      "epoch 26; iter: 0; batch classifier loss: 0.594988\n",
      "epoch 27; iter: 0; batch classifier loss: 0.609899\n",
      "epoch 28; iter: 0; batch classifier loss: 0.599761\n",
      "epoch 29; iter: 0; batch classifier loss: 0.597016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.572456\n",
      "epoch 31; iter: 0; batch classifier loss: 0.619520\n",
      "epoch 32; iter: 0; batch classifier loss: 0.586460\n",
      "epoch 33; iter: 0; batch classifier loss: 0.568610\n",
      "epoch 34; iter: 0; batch classifier loss: 0.601817\n",
      "epoch 35; iter: 0; batch classifier loss: 0.625406\n",
      "epoch 36; iter: 0; batch classifier loss: 0.591231\n",
      "epoch 37; iter: 0; batch classifier loss: 0.550536\n",
      "epoch 38; iter: 0; batch classifier loss: 0.623876\n",
      "epoch 39; iter: 0; batch classifier loss: 0.549685\n",
      "epoch 40; iter: 0; batch classifier loss: 0.556085\n",
      "epoch 41; iter: 0; batch classifier loss: 0.613207\n",
      "epoch 42; iter: 0; batch classifier loss: 0.553269\n",
      "epoch 43; iter: 0; batch classifier loss: 0.577534\n",
      "epoch 44; iter: 0; batch classifier loss: 0.656813\n",
      "epoch 45; iter: 0; batch classifier loss: 0.542904\n",
      "epoch 46; iter: 0; batch classifier loss: 0.553674\n",
      "epoch 47; iter: 0; batch classifier loss: 0.518710\n",
      "epoch 48; iter: 0; batch classifier loss: 0.613794\n",
      "epoch 49; iter: 0; batch classifier loss: 0.599886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x2dabde1a808>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_nodebias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model_nodebias.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_valid = plain_model_nodebias.predict(dataset_orig_valid)\n",
    "dataset_nodebiasing_test = plain_model_nodebias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.384561\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.348620\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.673333\n",
      "Balanced accuracy = 0.5166\n",
      "Statistical parity difference = -0.3486\n",
      "Disparate impact = 0.6343\n",
      "Average odds difference = -0.3912\n",
      "Equal opportunity difference = -0.2823\n",
      "Theil index = 0.1596\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "\n",
    "# Other metrics\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_nodebiasing_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores for ROC\n",
    "dataset_nodebiasing_valid.scores = plain_model_nodebias.predict_proba(dataset_orig_valid).reshape(-1,1)\n",
    "dataset_nodebiasing_test.scores = plain_model_nodebias.predict_proba(dataset_orig_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "plain_model_debias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=True,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.734769; batch adversarial loss: 0.652179\n",
      "epoch 1; iter: 0; batch classifier loss: 0.682632; batch adversarial loss: 0.660819\n",
      "epoch 2; iter: 0; batch classifier loss: 0.657078; batch adversarial loss: 0.603071\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590027; batch adversarial loss: 0.633419\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617300; batch adversarial loss: 0.729237\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619472; batch adversarial loss: 0.679605\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596630; batch adversarial loss: 0.744469\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632444; batch adversarial loss: 0.704037\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586759; batch adversarial loss: 0.700169\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616563; batch adversarial loss: 0.586475\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583529; batch adversarial loss: 0.591621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.619433; batch adversarial loss: 0.699889\n",
      "epoch 12; iter: 0; batch classifier loss: 0.584925; batch adversarial loss: 0.753784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539478; batch adversarial loss: 0.646811\n",
      "epoch 14; iter: 0; batch classifier loss: 0.606559; batch adversarial loss: 0.647490\n",
      "epoch 15; iter: 0; batch classifier loss: 0.656022; batch adversarial loss: 0.652043\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594872; batch adversarial loss: 0.692128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.589886; batch adversarial loss: 0.681446\n",
      "epoch 18; iter: 0; batch classifier loss: 0.616250; batch adversarial loss: 0.725135\n",
      "epoch 19; iter: 0; batch classifier loss: 0.694074; batch adversarial loss: 0.704888\n",
      "epoch 20; iter: 0; batch classifier loss: 0.595175; batch adversarial loss: 0.712376\n",
      "epoch 21; iter: 0; batch classifier loss: 0.666654; batch adversarial loss: 0.749421\n",
      "epoch 22; iter: 0; batch classifier loss: 0.652027; batch adversarial loss: 0.730178\n",
      "epoch 23; iter: 0; batch classifier loss: 0.662515; batch adversarial loss: 0.702217\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544534; batch adversarial loss: 0.678103\n",
      "epoch 25; iter: 0; batch classifier loss: 0.568137; batch adversarial loss: 0.682198\n",
      "epoch 26; iter: 0; batch classifier loss: 0.614113; batch adversarial loss: 0.814333\n",
      "epoch 27; iter: 0; batch classifier loss: 0.599766; batch adversarial loss: 0.677289\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529347; batch adversarial loss: 0.773080\n",
      "epoch 29; iter: 0; batch classifier loss: 0.620433; batch adversarial loss: 0.731580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.625925; batch adversarial loss: 0.768143\n",
      "epoch 31; iter: 0; batch classifier loss: 0.584350; batch adversarial loss: 0.710888\n",
      "epoch 32; iter: 0; batch classifier loss: 0.595683; batch adversarial loss: 0.705107\n",
      "epoch 33; iter: 0; batch classifier loss: 0.620373; batch adversarial loss: 0.679302\n",
      "epoch 34; iter: 0; batch classifier loss: 0.633376; batch adversarial loss: 0.729439\n",
      "epoch 35; iter: 0; batch classifier loss: 0.628486; batch adversarial loss: 0.825125\n",
      "epoch 36; iter: 0; batch classifier loss: 0.644089; batch adversarial loss: 0.697600\n",
      "epoch 37; iter: 0; batch classifier loss: 0.671857; batch adversarial loss: 0.798129\n",
      "epoch 38; iter: 0; batch classifier loss: 0.615268; batch adversarial loss: 0.748310\n",
      "epoch 39; iter: 0; batch classifier loss: 0.610339; batch adversarial loss: 0.736714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.622866; batch adversarial loss: 0.752073\n",
      "epoch 41; iter: 0; batch classifier loss: 0.651540; batch adversarial loss: 0.703689\n",
      "epoch 42; iter: 0; batch classifier loss: 0.624081; batch adversarial loss: 0.718398\n",
      "epoch 43; iter: 0; batch classifier loss: 0.653298; batch adversarial loss: 0.705169\n",
      "epoch 44; iter: 0; batch classifier loss: 0.660712; batch adversarial loss: 0.712320\n",
      "epoch 45; iter: 0; batch classifier loss: 0.736435; batch adversarial loss: 0.789353\n",
      "epoch 46; iter: 0; batch classifier loss: 0.673282; batch adversarial loss: 0.767371\n",
      "epoch 47; iter: 0; batch classifier loss: 0.548670; batch adversarial loss: 0.783047\n",
      "epoch 48; iter: 0; batch classifier loss: 0.613608; batch adversarial loss: 0.762751\n",
      "epoch 49; iter: 0; batch classifier loss: 0.642486; batch adversarial loss: 0.757692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x2dacd56c948>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_debias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = plain_model_debias.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = plain_model_debias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.547368\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.551402\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.600000\n",
      "Balanced accuracy = 0.5650\n",
      "Statistical parity difference = 0.5514\n",
      "Disparate impact = 2.2292\n",
      "Average odds difference = 0.6141\n",
      "Equal opportunity difference = 0.4875\n",
      "Theil index = 0.3484\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "display(Markdown(\"#### Plain model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "\n",
    "#Other metrics\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_debiasing_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: Reject Option Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.673333\n",
      "Balanced accuracy = 0.5166\n",
      "Statistical parity difference = -0.3486\n",
      "Disparate impact = 0.6343\n",
      "Average odds difference = -0.3912\n",
      "Equal opportunity difference = -0.2823\n",
      "Theil index = 0.1596\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy())\n",
    "\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_nodebiasing_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(dataset_orig_valid,dataset_nodebiasing_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.5940\n",
      "Optimal ROC margin = 0.0580\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions from Test Set with ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.620000\n",
      "Balanced accuracy = 0.6472\n",
      "Statistical parity difference = 0.0396\n",
      "Disparate impact = 1.0799\n",
      "Average odds difference = 0.0718\n",
      "Equal opportunity difference = 0.0457\n",
      "Theil index = 0.3906\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_test = ROC.predict(dataset_nodebiasing_test)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_transf_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy()) \n",
    "\n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "F. Kamiran, and T. Claders,\"Data preprocessing techniques for classification without discrimination\",\n",
    "Knowledge and Information Systems, 33(1):1–33, 2012. \n",
    "\n",
    "B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning\",\n",
    "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.\n",
    "\n",
    "F. Kamiran, A. Karim, and X. Zhang,  \"Decision theory for discrimination-aware classification\",\n",
    "In IEEE International Conference on Data Mining, pp. 924–929, 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
