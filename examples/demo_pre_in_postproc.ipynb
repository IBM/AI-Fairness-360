{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of Reweighing pre-processing, Adversarial Debiasing in-processing and Reject Option Classification (ROC) post-processing algorithms for bias mitigation.\n",
    "- Load imports\n",
    "- Dataset\n",
    "    * Load Adult, COMPAS, or German dataset and set privileged and unprivileged groups\n",
    "    * Divide the dataset into training, validation, and testing partitions\n",
    "    * Show dataset properties\n",
    "- Pre-processing: Reweighing.\n",
    "    * Show difference in mean outcomes for original training data\n",
    "    * Assign weights with reweighing\n",
    "    * Show difference in mean outcomes for transformed training data\n",
    "- In-processing: Adversarial Debiasing.\n",
    "    * Train model without debiasing, predict, and show metrics\n",
    "    * Train model with debiasing, predict, and show metrics\n",
    "- Post-processing: Reject Option Classification (ROC).\n",
    "    * Show metrics for test set from Adversarial Debiasing without debiasing\n",
    "    * Fit ROC model\n",
    "    * Transform labels and show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Avoid deprecation warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import interactive, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#     dataset_orig = AdultDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['race'])\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "#     dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['age'])\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 0}]\n",
    "        unprivileged_groups = [{'sex': 1}]\n",
    "        dataset_orig = load_preproc_data_compas(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]  \n",
    "        dataset_orig = load_preproc_data_compas(['race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up training data and display properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing: Reweighing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights = 1.000000 , 1.000000, 1.000000, ...\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.085684\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Weights = %f , %f, %f, ...\" % (dataset_orig_train.instance_weights[1], dataset_orig_train.instance_weights[2], \\\n",
    "                                    dataset_orig_train.instance_weights[3]))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(dataset_orig_train)\n",
    "dataset_transf_train = RW.transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for reweighted training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights = 0.962556 , 1.107728, 1.107728, ...\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Weights = %8f , %8f, %8f, ...\" % (dataset_transf_train.instance_weights[1], dataset_transf_train.instance_weights[2], \\\n",
    "                                    dataset_transf_train.instance_weights[3]))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-processing: Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session() \n",
    "plain_model_nodebias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.652186\n",
      "epoch 1; iter: 0; batch classifier loss: 0.625617\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585623\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539420\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579216\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531723\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537198\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605551\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565381\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551469\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481968\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564440\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553404\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554652\n",
      "epoch 14; iter: 0; batch classifier loss: 0.577627\n",
      "epoch 15; iter: 0; batch classifier loss: 0.547541\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532641\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550717\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528838\n",
      "epoch 19; iter: 0; batch classifier loss: 0.570395\n",
      "epoch 20; iter: 0; batch classifier loss: 0.568051\n",
      "epoch 21; iter: 0; batch classifier loss: 0.605055\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.613383\n",
      "epoch 24; iter: 0; batch classifier loss: 0.588328\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530061\n",
      "epoch 26; iter: 0; batch classifier loss: 0.534856\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513996\n",
      "epoch 28; iter: 0; batch classifier loss: 0.530265\n",
      "epoch 29; iter: 0; batch classifier loss: 0.668024\n",
      "epoch 30; iter: 0; batch classifier loss: 0.530485\n",
      "epoch 31; iter: 0; batch classifier loss: 0.564731\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.546134\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547767\n",
      "epoch 35; iter: 0; batch classifier loss: 0.602737\n",
      "epoch 36; iter: 0; batch classifier loss: 0.555608\n",
      "epoch 37; iter: 0; batch classifier loss: 0.501483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519091\n",
      "epoch 39; iter: 0; batch classifier loss: 0.607730\n",
      "epoch 40; iter: 0; batch classifier loss: 0.594589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.637092\n",
      "epoch 42; iter: 0; batch classifier loss: 0.553102\n",
      "epoch 43; iter: 0; batch classifier loss: 0.540746\n",
      "epoch 44; iter: 0; batch classifier loss: 0.553540\n",
      "epoch 45; iter: 0; batch classifier loss: 0.519858\n",
      "epoch 46; iter: 0; batch classifier loss: 0.539270\n",
      "epoch 47; iter: 0; batch classifier loss: 0.598707\n",
      "epoch 48; iter: 0; batch classifier loss: 0.517129\n",
      "epoch 49; iter: 0; batch classifier loss: 0.604602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x25428db58c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_nodebias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model_nodebias.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_valid = plain_model_nodebias.predict(dataset_orig_valid)\n",
    "dataset_nodebiasing_test = plain_model_nodebias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.127753\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.111111\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.680000\n",
      "Balanced accuracy = 0.5067\n",
      "Statistical parity difference = -0.1111\n",
      "Disparate impact = 0.8889\n",
      "Average odds difference = -0.1167\n",
      "Equal opportunity difference = -0.1000\n",
      "Theil index = 0.0781\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "\n",
    "# Other metrics\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_nodebiasing_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "plain_model_debias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=True,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.772944; batch adversarial loss: 0.720876\n",
      "epoch 1; iter: 0; batch classifier loss: 0.732564; batch adversarial loss: 0.724742\n",
      "epoch 2; iter: 0; batch classifier loss: 0.702260; batch adversarial loss: 0.711225\n",
      "epoch 3; iter: 0; batch classifier loss: 0.678974; batch adversarial loss: 0.719904\n",
      "epoch 4; iter: 0; batch classifier loss: 0.660917; batch adversarial loss: 0.750913\n",
      "epoch 5; iter: 0; batch classifier loss: 0.678752; batch adversarial loss: 0.728699\n",
      "epoch 6; iter: 0; batch classifier loss: 0.617788; batch adversarial loss: 0.724927\n",
      "epoch 7; iter: 0; batch classifier loss: 0.628121; batch adversarial loss: 0.733563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.678718; batch adversarial loss: 0.728306\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590913; batch adversarial loss: 0.735855\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568394; batch adversarial loss: 0.723743\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592545; batch adversarial loss: 0.732843\n",
      "epoch 12; iter: 0; batch classifier loss: 0.634384; batch adversarial loss: 0.708794\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572310; batch adversarial loss: 0.718885\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563382; batch adversarial loss: 0.710993\n",
      "epoch 15; iter: 0; batch classifier loss: 0.650155; batch adversarial loss: 0.729090\n",
      "epoch 16; iter: 0; batch classifier loss: 0.612505; batch adversarial loss: 0.720887\n",
      "epoch 17; iter: 0; batch classifier loss: 0.585927; batch adversarial loss: 0.735062\n",
      "epoch 18; iter: 0; batch classifier loss: 0.571527; batch adversarial loss: 0.716581\n",
      "epoch 19; iter: 0; batch classifier loss: 0.599590; batch adversarial loss: 0.726984\n",
      "epoch 20; iter: 0; batch classifier loss: 0.594866; batch adversarial loss: 0.718864\n",
      "epoch 21; iter: 0; batch classifier loss: 0.640844; batch adversarial loss: 0.702537\n",
      "epoch 22; iter: 0; batch classifier loss: 0.615682; batch adversarial loss: 0.716770\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588055; batch adversarial loss: 0.714996\n",
      "epoch 24; iter: 0; batch classifier loss: 0.576634; batch adversarial loss: 0.711641\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557881; batch adversarial loss: 0.705441\n",
      "epoch 26; iter: 0; batch classifier loss: 0.591009; batch adversarial loss: 0.703820\n",
      "epoch 27; iter: 0; batch classifier loss: 0.549217; batch adversarial loss: 0.699617\n",
      "epoch 28; iter: 0; batch classifier loss: 0.559669; batch adversarial loss: 0.714941\n",
      "epoch 29; iter: 0; batch classifier loss: 0.541521; batch adversarial loss: 0.698567\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510673; batch adversarial loss: 0.703543\n",
      "epoch 31; iter: 0; batch classifier loss: 0.553757; batch adversarial loss: 0.687497\n",
      "epoch 32; iter: 0; batch classifier loss: 0.583756; batch adversarial loss: 0.694300\n",
      "epoch 33; iter: 0; batch classifier loss: 0.549624; batch adversarial loss: 0.682608\n",
      "epoch 34; iter: 0; batch classifier loss: 0.581839; batch adversarial loss: 0.693741\n",
      "epoch 35; iter: 0; batch classifier loss: 0.562343; batch adversarial loss: 0.682411\n",
      "epoch 36; iter: 0; batch classifier loss: 0.607957; batch adversarial loss: 0.683783\n",
      "epoch 37; iter: 0; batch classifier loss: 0.614364; batch adversarial loss: 0.702852\n",
      "epoch 38; iter: 0; batch classifier loss: 0.531772; batch adversarial loss: 0.686299\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500435; batch adversarial loss: 0.689979\n",
      "epoch 40; iter: 0; batch classifier loss: 0.618996; batch adversarial loss: 0.688158\n",
      "epoch 41; iter: 0; batch classifier loss: 0.573520; batch adversarial loss: 0.670536\n",
      "epoch 42; iter: 0; batch classifier loss: 0.546000; batch adversarial loss: 0.670373\n",
      "epoch 43; iter: 0; batch classifier loss: 0.554354; batch adversarial loss: 0.670663\n",
      "epoch 44; iter: 0; batch classifier loss: 0.606900; batch adversarial loss: 0.671099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.574497; batch adversarial loss: 0.677126\n",
      "epoch 46; iter: 0; batch classifier loss: 0.573215; batch adversarial loss: 0.666858\n",
      "epoch 47; iter: 0; batch classifier loss: 0.519300; batch adversarial loss: 0.670357\n",
      "epoch 48; iter: 0; batch classifier loss: 0.552512; batch adversarial loss: 0.666460\n",
      "epoch 49; iter: 0; batch classifier loss: 0.573362; batch adversarial loss: 0.648586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x2542a0aeec8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_debias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = plain_model_debias.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = plain_model_debias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.127753\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.066667\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.680000\n",
      "Balanced accuracy = 0.5009\n",
      "Statistical parity difference = -0.0667\n",
      "Disparate impact = 0.9333\n",
      "Average odds difference = -0.0667\n",
      "Equal opportunity difference = -0.0667\n",
      "Theil index = 0.0715\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "display(Markdown(\"#### Plain model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "\n",
    "#Other metrics\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_debiasing_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: Reject Option Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.680000\n",
      "Balanced accuracy = 0.5067\n",
      "Statistical parity difference = -0.1111\n",
      "Disparate impact = 0.8889\n",
      "Average odds difference = -0.1167\n",
      "Equal opportunity difference = -0.1000\n",
      "Theil index = 0.0781\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy())\n",
    "\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_nodebiasing_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(dataset_orig_valid,dataset_nodebiasing_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.7128\n",
      "Optimal ROC margin = 0.0820\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions from Test Set with ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.493333\n",
      "Balanced accuracy = 0.5617\n",
      "Statistical parity difference = 0.0857\n",
      "Disparate impact = 1.2727\n",
      "Average odds difference = 0.0704\n",
      "Equal opportunity difference = 0.1242\n",
      "Theil index = 0.5954\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_test = ROC.predict(dataset_nodebiasing_test)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_transf_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy()) \n",
    "\n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "F. Kamiran, and T. Claders,\"Data preprocessing techniques for classification without discrimination\",\n",
    "Knowledge and Information Systems, 33(1):1–33, 2012. \n",
    "\n",
    "B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning\",\n",
    "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.\n",
    "\n",
    "F. Kamiran, A. Karim, and X. Zhang,  \"Decision theory for discrimination-aware classification\",\n",
    "In IEEE International Conference on Data Mining, pp. 924–929, 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
