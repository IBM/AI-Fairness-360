{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of Reweighing pre-processing, Adversarial Debiasing in-processing and Reject Option Classification (ROC) post-processing algorithms for bias mitigation.\n",
    "- Load imports\n",
    "- Dataset\n",
    "    * Load Adult, COMPAS, or German dataset and set privileged and unprivileged groups\n",
    "    * Divide the dataset into training, validation, and testing partitions\n",
    "    * Show dataset properties\n",
    "- Pre-processing: Reweighing.\n",
    "    * Show difference in mean outcomes for original training data\n",
    "    * Assign weights with reweighing\n",
    "    * Show difference in mean outcomes for transformed training data\n",
    "- In-processing: Adversarial Debiasing.\n",
    "    * Train model without debiasing, predict, and show metrics\n",
    "    * Train model with debiasing, predict, and show metrics\n",
    "- Post-processing: Reject Option Classification (ROC).\n",
    "    * Show metrics for test set from Adversarial Debiasing without debiasing\n",
    "    * Fit ROC model\n",
    "    * Transform labels and show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from warnings import warn \n",
    "\n",
    "# Avoid deprecation warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import interactive, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#     dataset_orig = AdultDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['race'])\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "#     dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['age'])\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 0}]\n",
    "        unprivileged_groups = [{'sex': 1}]\n",
    "        dataset_orig = load_preproc_data_compas(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]  \n",
    "        dataset_orig = load_preproc_data_compas(['race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up training data and display properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing: Reweighing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights = 1.000000 , 1.000000, 1.000000, ...\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.097778\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Weights = %f , %f, %f, ...\" % (dataset_orig_train.instance_weights[1], dataset_orig_train.instance_weights[2], \\\n",
    "                                    dataset_orig_train.instance_weights[3]))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(dataset_orig_train)\n",
    "dataset_transf_train = RW.transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for reweighted training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights = 0.956349 , 0.956349, 1.112245, ...\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Weights = %8f , %8f, %8f, ...\" % (dataset_transf_train.instance_weights[1], dataset_transf_train.instance_weights[2], \\\n",
    "                                    dataset_transf_train.instance_weights[3]))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-processing: Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session() \n",
    "plain_model_nodebias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.705588\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649443\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.604294\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576895\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528867\n",
      "epoch 6; iter: 0; batch classifier loss: 0.644497\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615819\n",
      "epoch 8; iter: 0; batch classifier loss: 0.631111\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547435\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576678\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582958\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552135\n",
      "epoch 13; iter: 0; batch classifier loss: 0.585561\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539198\n",
      "epoch 15; iter: 0; batch classifier loss: 0.623623\n",
      "epoch 16; iter: 0; batch classifier loss: 0.598153\n",
      "epoch 17; iter: 0; batch classifier loss: 0.597544\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556966\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506808\n",
      "epoch 20; iter: 0; batch classifier loss: 0.562685\n",
      "epoch 21; iter: 0; batch classifier loss: 0.598550\n",
      "epoch 22; iter: 0; batch classifier loss: 0.622384\n",
      "epoch 23; iter: 0; batch classifier loss: 0.549427\n",
      "epoch 24; iter: 0; batch classifier loss: 0.538035\n",
      "epoch 25; iter: 0; batch classifier loss: 0.602872\n",
      "epoch 26; iter: 0; batch classifier loss: 0.549921\n",
      "epoch 27; iter: 0; batch classifier loss: 0.593130\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557126\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505159\n",
      "epoch 30; iter: 0; batch classifier loss: 0.642828\n",
      "epoch 31; iter: 0; batch classifier loss: 0.595856\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525119\n",
      "epoch 33; iter: 0; batch classifier loss: 0.571231\n",
      "epoch 34; iter: 0; batch classifier loss: 0.578417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.563437\n",
      "epoch 36; iter: 0; batch classifier loss: 0.563610\n",
      "epoch 37; iter: 0; batch classifier loss: 0.547978\n",
      "epoch 38; iter: 0; batch classifier loss: 0.570851\n",
      "epoch 39; iter: 0; batch classifier loss: 0.541031\n",
      "epoch 40; iter: 0; batch classifier loss: 0.563402\n",
      "epoch 41; iter: 0; batch classifier loss: 0.514929\n",
      "epoch 42; iter: 0; batch classifier loss: 0.555526\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542680\n",
      "epoch 44; iter: 0; batch classifier loss: 0.565084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.568865\n",
      "epoch 46; iter: 0; batch classifier loss: 0.535576\n",
      "epoch 47; iter: 0; batch classifier loss: 0.598330\n",
      "epoch 48; iter: 0; batch classifier loss: 0.553983\n",
      "epoch 49; iter: 0; batch classifier loss: 0.603002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x1f4c3e76088>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_nodebias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model_nodebias.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_valid = plain_model_nodebias.predict(dataset_orig_valid)\n",
    "dataset_nodebiasing_test = plain_model_nodebias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.400000\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.365854\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.720000\n",
      "Test set: Balanced classification accuracy = 0.509317\n",
      "Test set: Disparate impact = 0.634146\n",
      "Test set: Equal opportunity difference = -0.333333\n",
      "Test set: Average odds difference = -0.416667\n",
      "Test set: Theil_index = 0.127632\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "# Compute scores for ROC\n",
    "dataset_nodebiasing_valid.scores = plain_model_nodebias.predict_proba(dataset_orig_valid).reshape(-1,1)\n",
    "dataset_nodebiasing_test.scores = plain_model_nodebias.predict_proba(dataset_orig_test).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "sess = tf.Session()\n",
    "plain_model_debias = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=True,\n",
    "                           sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.672484; batch adversarial loss: 0.656056\n",
      "epoch 1; iter: 0; batch classifier loss: 0.683665; batch adversarial loss: 0.619799\n",
      "epoch 2; iter: 0; batch classifier loss: 0.645837; batch adversarial loss: 0.644092\n",
      "epoch 3; iter: 0; batch classifier loss: 0.599088; batch adversarial loss: 0.596543\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634671; batch adversarial loss: 0.610302\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544876; batch adversarial loss: 0.607539\n",
      "epoch 6; iter: 0; batch classifier loss: 0.651467; batch adversarial loss: 0.575780\n",
      "epoch 7; iter: 0; batch classifier loss: 0.653255; batch adversarial loss: 0.610739\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579653; batch adversarial loss: 0.616999\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560469; batch adversarial loss: 0.584139\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520689; batch adversarial loss: 0.637061\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537064; batch adversarial loss: 0.662237\n",
      "epoch 12; iter: 0; batch classifier loss: 0.592180; batch adversarial loss: 0.635091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496653; batch adversarial loss: 0.592221\n",
      "epoch 14; iter: 0; batch classifier loss: 0.598732; batch adversarial loss: 0.649858\n",
      "epoch 15; iter: 0; batch classifier loss: 0.593922; batch adversarial loss: 0.588861\n",
      "epoch 16; iter: 0; batch classifier loss: 0.632204; batch adversarial loss: 0.626118\n",
      "epoch 17; iter: 0; batch classifier loss: 0.561657; batch adversarial loss: 0.637305\n",
      "epoch 18; iter: 0; batch classifier loss: 0.641035; batch adversarial loss: 0.598052\n",
      "epoch 19; iter: 0; batch classifier loss: 0.572751; batch adversarial loss: 0.657062\n",
      "epoch 20; iter: 0; batch classifier loss: 0.603344; batch adversarial loss: 0.636843\n",
      "epoch 21; iter: 0; batch classifier loss: 0.577140; batch adversarial loss: 0.633854\n",
      "epoch 22; iter: 0; batch classifier loss: 0.512823; batch adversarial loss: 0.625243\n",
      "epoch 23; iter: 0; batch classifier loss: 0.570977; batch adversarial loss: 0.678118\n",
      "epoch 24; iter: 0; batch classifier loss: 0.557642; batch adversarial loss: 0.568389\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520173; batch adversarial loss: 0.690096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.572445; batch adversarial loss: 0.652382\n",
      "epoch 27; iter: 0; batch classifier loss: 0.602638; batch adversarial loss: 0.623790\n",
      "epoch 28; iter: 0; batch classifier loss: 0.546569; batch adversarial loss: 0.631071\n",
      "epoch 29; iter: 0; batch classifier loss: 0.543473; batch adversarial loss: 0.632583\n",
      "epoch 30; iter: 0; batch classifier loss: 0.607426; batch adversarial loss: 0.623002\n",
      "epoch 31; iter: 0; batch classifier loss: 0.613303; batch adversarial loss: 0.651097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.604840; batch adversarial loss: 0.642805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.561815; batch adversarial loss: 0.632933\n",
      "epoch 34; iter: 0; batch classifier loss: 0.539414; batch adversarial loss: 0.663116\n",
      "epoch 35; iter: 0; batch classifier loss: 0.606202; batch adversarial loss: 0.630583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.557263; batch adversarial loss: 0.650335\n",
      "epoch 37; iter: 0; batch classifier loss: 0.638472; batch adversarial loss: 0.648237\n",
      "epoch 38; iter: 0; batch classifier loss: 0.597013; batch adversarial loss: 0.675402\n",
      "epoch 39; iter: 0; batch classifier loss: 0.583516; batch adversarial loss: 0.629908\n",
      "epoch 40; iter: 0; batch classifier loss: 0.532334; batch adversarial loss: 0.640401\n",
      "epoch 41; iter: 0; batch classifier loss: 0.582474; batch adversarial loss: 0.683157\n",
      "epoch 42; iter: 0; batch classifier loss: 0.573594; batch adversarial loss: 0.640547\n",
      "epoch 43; iter: 0; batch classifier loss: 0.525806; batch adversarial loss: 0.641649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.592777; batch adversarial loss: 0.639554\n",
      "epoch 45; iter: 0; batch classifier loss: 0.549323; batch adversarial loss: 0.614415\n",
      "epoch 46; iter: 0; batch classifier loss: 0.506904; batch adversarial loss: 0.651459\n",
      "epoch 47; iter: 0; batch classifier loss: 0.614714; batch adversarial loss: 0.681480\n",
      "epoch 48; iter: 0; batch classifier loss: 0.561063; batch adversarial loss: 0.654666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.493891; batch adversarial loss: 0.597486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x1f4c6259188>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model_debias.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = plain_model_debias.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = plain_model_debias.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.109474\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.064220\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.746667\n",
      "Test set: Balanced classification accuracy = 0.506832\n",
      "Test set: Disparate impact = 1.068627\n",
      "Test set: Equal opportunity difference = 0.060976\n",
      "Test set: Average odds difference = 0.067525\n",
      "Test set: Theil_index = 0.085861\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "#metric_test_bef = compute_metrics(dataset_orig_test, dataset_nodebiasing_test, \n",
    "#                unprivileged_groups, privileged_groups)\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: Reject Option Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.720000\n",
      "Balanced accuracy = 0.5093\n",
      "Statistical parity difference = -0.3659\n",
      "Disparate impact = 0.6341\n",
      "Average odds difference = -0.4167\n",
      "Equal opportunity difference = -0.3333\n",
      "Theil index = 0.1276\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy())\n",
    "\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_nodebiasing_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(dataset_orig_valid,dataset_nodebiasing_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.5841\n",
      "Optimal ROC margin = 0.0085\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions from Test Set with ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.593333\n",
      "Balanced accuracy = 0.5857\n",
      "Statistical parity difference = 0.0349\n",
      "Disparate impact = 1.0634\n",
      "Average odds difference = 0.0505\n",
      "Equal opportunity difference = 0.0085\n",
      "Theil index = 0.4063\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_test = ROC.predict(dataset_nodebiasing_test)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "classified_metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_transf_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Classification accuracy = %f\" % classified_metric_test.accuracy()) \n",
    "\n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "F. Kamiran, and T. Claders,\"Data preprocessing techniques for classification without discrimination\",\n",
    "Knowledge and Information Systems, 33(1):1–33, 2012. \n",
    "\n",
    "B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning\",\n",
    "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.\n",
    "\n",
    "F. Kamiran, A. Karim, and X. Zhang,  \"Decision theory for discrimination-aware classification\",\n",
    "In IEEE International Conference on Data Mining, pp. 924–929, 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
