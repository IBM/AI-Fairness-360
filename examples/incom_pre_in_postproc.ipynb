{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of Reweighing pre-processing, Adversarial Debiasing in-processing and Reject Option Classification (ROC) post-processing algorithms for bias mitigation.\n",
    "- Load imports\n",
    "- Dataset\n",
    "    * Load Adult, COMPAS, or German dataset and set privileged and unprivileged groups\n",
    "    * Divide the dataset into training, validation, and testing partitions\n",
    "    * Show dataset properties\n",
    "- Pre-processing: Reweighing.\n",
    "    * Show difference in mean outcomes for original training data\n",
    "    * Assign weights with reweighing\n",
    "    * Show difference in mean outcomes for transformed training data\n",
    "- In-processing: Adversarial Debiasing.\n",
    "    * Train model without debiasing, predict, and show metrics\n",
    "    * Train model with debiasing, predict, and show metrics\n",
    "- Post-processing: Reject Option Classification (ROC).\n",
    "    * Show metrics for test set from Adversarial Debiasing without debiasing\n",
    "    * Fit ROC model\n",
    "    * Transform labels and show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from warnings import warn \n",
    "\n",
    "# Avoid deprecation warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from ipywidgets import interactive, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#     dataset_orig = AdultDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['race'])\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "#     dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['age'])\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 0}]\n",
    "        unprivileged_groups = [{'sex': 1}]\n",
    "        dataset_orig = load_preproc_data_compas(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]  \n",
    "        dataset_orig = load_preproc_data_compas(['race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up training data and display properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing: Reweighing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Crear un objeto de la clase BinaryLabelDatasetMetric cuyo constructor recibe por parámetros el dataset de entrenamiento, \n",
    "# el array de tuplas de grupos desprivilegiados y el array de tuplas de grupos privilegiados. \n",
    "# 2. Llamar a su método mean_difference() e imprimir el valor devuelto (un float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear un objeto de la clase Reweighing(grupos desprivilegiados, gurpos privilegiados)\n",
    "# 2. Llamar a su método fit(dataset) con el dataset de entrenamiento\n",
    "# 3. Llamar a su método transform(dataset) con el dataset de entrenamiento que devuelve el dataset transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for reweighted training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Imprimir la media de diferencias del dataset transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-processing: Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to False\n",
    "# 1. Iniciar una sesión de tensorflow con tf.Session() \n",
    "# 2. Crear un objeto de la clase AdversarialDebiasing(grupo privilegiado, grupo desprivilegiado, 'plain_classifier', \n",
    "# booleano de si queremos que haya un adversario (en este caso False), la sesión de tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Llamar a su método fit(dataset) con el dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "# 1. Llamar a su método predict(dataset) que devuelve un dataset con las labels predichas para el dataset de entrenamiento, \n",
    "# validación y testeo. Guardar cada uno en 3 datasets distintos (entre sí y respecto a los dataset de entrada)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "# 1. Imprimir la media de diferencias del dataset de entrenamiento y el dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# 1. Crear un objeto de la clase ClassificationMetric(dataset no predicho, dataset predicho, grupos desprivilegiados, \n",
    "# grupos privilegiados) con el dataset de test\n",
    "# 2. Llamar a su método accuracy() e imprimir el valor devuelto (un float)\n",
    "\n",
    "\n",
    "# Other metrics\n",
    "# 1. Llamar a la función compute_metrics(dataset no predicho, dataset predicho, grupos desprivilegiados, grupos privilegiados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores for ROC\n",
    "# 1. Llamar al método del objeto de la clase AdversarialDebiasing predict_proba(dataset no predicho) \n",
    "# con el dataset de validación y el de test\n",
    "# 2. Transformar el valor devuelto en una columna con reshape y guardar los valores en el atributo scores de los \n",
    "# datasets predichos de validación y de test respectivamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cerrar la sesión de tf con su método close()\n",
    "# 2. Llamar a la función de tf reset_default_graph()\n",
    "# 3. Abrir una nueva sesión de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "# 1. Volver a crear un objeto de la clase AdversarialDebiasing con debias=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Entrenar el modelo sobre el dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "# 1. Predecir el dataset de entrenamiento y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "# 1. Mostrar la media de las diferencias del dataset de entrenamiento y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# 1. Mostrar la precisión del dataset test\n",
    "\n",
    "\n",
    "# Other metrics\n",
    "# 1. Mostrar el resto de métricas del dataset test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing: Reject Option Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show metrics for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the test set\n",
    "# Accuracy \n",
    "# 1. Mostrar la precisión del dataset test sin debias\n",
    "\n",
    "# Other metrics\n",
    "# 1. Mostrar el resto de métricas del dataset test sin debias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear un objeto de la clase RejectOptionClassification(grupos desprivilegiados, gurpos privilegiados, \n",
    "# límite inferior de prueba, limite superior de prueba, número de thresholds, número de márgenes, métrica a optimizar, \n",
    "# límite superior de la métrica, límite inferior de la métrica)\n",
    "# 2. Llamar a su método fit(dataset no predicho, dataset predicho) con el dataset de validación. Devuelve el ROC entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imprimir el classification_threshold y el ROC_margin del ROC entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions from Test Set with ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the transformed test set\n",
    "# 1. Predecir con predict(dataset predicho) las nuevas predicciones\n",
    "\n",
    "# Accuracy \n",
    "# 1. Mostrar la precisión del dataset transformado test sin debias\n",
    "\n",
    "# Other metrics\n",
    "# 1. Mostrar el resto de métricas del dataset transformado test sin debias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "F. Kamiran, and T. Claders,\"Data preprocessing techniques for classification without discrimination\",\n",
    "Knowledge and Information Systems, 33(1):1–33, 2012. \n",
    "\n",
    "B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning\",\n",
    "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.\n",
    "\n",
    "F. Kamiran, A. Karim, and X. Zhang,  \"Decision theory for discrimination-aware classification\",\n",
    "In IEEE International Conference on Data Mining, pp. 924–929, 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
