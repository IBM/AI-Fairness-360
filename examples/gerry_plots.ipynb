{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from aif360.algorithms.inprocessing.gerryfair_classifier import *\n",
    "from aif360.algorithms.inprocessing.gerryfair.clean import *\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import *\n",
    "from aif360.algorithms.inprocessing.gerryfair.auditor import *\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import linear_model\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_classifiers_pareto(dataset, gamma_list=[0.002, 0.005, 0.01, 0.02, 0.05, 0.1], save_results=False):\n",
    "\n",
    "    ln_predictor = linear_model.LinearRegression()\n",
    "    svm_predictor = svm.LinearSVR()\n",
    "    tree_predictor = tree.DecisionTreeRegressor(max_depth=3)\n",
    "    kernel_predictor = KernelRidge(alpha=1.0, gamma=1.0, kernel='rbf')\n",
    "    predictor_dict = {'Linear': {'predictor': ln_predictor, 'iters': 10},\n",
    "                      'SVR': {'predictor': svm_predictor, 'iters': 10},\n",
    "                      'Tree': {'predictor': tree_predictor, 'iters': 10},\n",
    "                      'Kernel': {'predictor': kernel_predictor, 'iters': 10}}\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    for pred in predictor_dict:\n",
    "        print('Curr Predictor: {}'.format(pred))\n",
    "        predictor = predictor_dict[pred]['predictor']\n",
    "        max_iters = predictor_dict[pred]['iters']\n",
    "        fair_clf = Model(C=100, printflag=True, gamma=1, predictor=predictor, max_iters=max_iters)\n",
    "        fair_clf.set_options(max_iters=max_iters)\n",
    "        errors, fp_violations, fn_violations = fair_clf.pareto(dataset, gamma_list)\n",
    "        results_dict[pred] = {'errors': errors, 'fp_violations': fp_violations, 'fn_violations': fn_violations}\n",
    "        plt.plot(errors, fp_violations, label=pred)\n",
    "\n",
    "    if save_results:\n",
    "        pickle.dump(results_dict, open('results_dict_' + str(gamma_list) + '_gammas' + str(gamma_list) + '.pkl', 'wb'))\n",
    "\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Unfairness')\n",
    "    plt.legend()\n",
    "    plt.title('Error vs. Unfairness\\n(Communities & Crime Dataset)')\n",
    "    plt.show()\n",
    "    \n",
    "data_set = load_preproc_data_adult(sub_samp=50)\n",
    "multiple_classifiers_pareto(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_preproc_data_adult' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1724c0e7d50a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_preproc_data_adult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mfp_vs_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_preproc_data_adult' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "def fp_vs_fn(dataset, fair_model, gamma_list):\n",
    "    fp_auditor = Auditor(dataset, 'FP')\n",
    "    fn_auditor = Auditor(dataset, 'FN')\n",
    "    fp_violations = []\n",
    "    fn_violations = []\n",
    "    for g in gamma_list:\n",
    "        fair_model.set_options(gamma=g)\n",
    "        fair_model.fit(dataset)\n",
    "        predictions = (fair_model.predict(dataset)).labels\n",
    "        predictions_inv = [abs(1 - p) for p in predictions]\n",
    "        _, fp_diff = fp_auditor.audit(predictions)\n",
    "        _, fn_diff = fn_auditor.audit(predictions_inv)\n",
    "        fp_violations.append(fp_diff)\n",
    "        fn_violations.append(fn_diff)\n",
    "\n",
    "    print((fp_violations, fn_violations))\n",
    "\n",
    "    plt.plot(fp_violations, fn_violations, label='communities')\n",
    "    plt.xlabel('False Positive Disparity')\n",
    "    plt.ylabel('False Negative Disparity')\n",
    "    plt.legend()\n",
    "    plt.title('FP vs FN Unfairness')\n",
    "    plt.show()\n",
    "    \n",
    "C = 10\n",
    "print_flag = True\n",
    "gamma = .01\n",
    "max_iterations = 10\n",
    "fair_def = 'FP'\n",
    "fair_model = Model(C=C, printflag=print_flag, gamma=gamma, fairness_def=fair_def, max_iters=max_iterations)\n",
    "data_set = load_preproc_data_adult(sub_samp=50)\n",
    "gamma_list = [0.001, 0.002, 0.003, 0.004, 0.005, 0.0075, 0.01, 0.02, 0.03, 0.05]\n",
    "fp_vs_fn(data_set, fair_model, gamma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit method\n",
    "communities_all_errors, communities_violations = fair_model.fit(data_set,\n",
    "                                                 early_termination=True, return_values=True)\n",
    "# predict method\n",
    "dataset_yhat = fair_model.predict(data_set)\n",
    "\n",
    "# save heatmap\n",
    "fair_model.heatmap_path = 'heatmap_example'\n",
    "os.mkdir(fair_model.heatmap_path)\n",
    "fair_model.save_heatmap(fair_model.max_iters, data_set, dataset_yhat.labels, None, None, force_heatmap=True)\n",
    "\n",
    "# run & create pareto curves\n",
    "gamma_list = [.01, .02, .03, 1.0]\n",
    "fair_model.pareto(data_set, gamma_list)\n",
    "\n",
    "# auditing a classifier for unfairness\n",
    "# instantiate auditor\n",
    "auditor = Auditor(data_set, 'FP')\n",
    "group = auditor.get_group(dataset_yhat.labels, auditor.get_baseline(array_to_tuple(data_set.labels), array_to_tuple(dataset_yhat.labels)))\n",
    "print('gamma disparity: {}'.format(group.weighted_disparity))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}