{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "IOError: [Errno 2] File /Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/datasets/../data/raw/adult/adult.data does not exist: '/Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/datasets/../data/raw/adult/adult.data'\n",
      "To use this class, please download the following files:\n",
      "\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
      "\n",
      "and place them, as-is, in the folder:\n",
      "\n",
      "\t/Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/data/raw/adult\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/datasets/adult_dataset.py\", line 87, in __init__\n",
      "    skipinitialspace=True, na_values=na_values)\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/pandas/io/parsers.py\", line 676, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/pandas/io/parsers.py\", line 448, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/pandas/io/parsers.py\", line 880, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1114, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1891, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 673, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File /Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/datasets/../data/raw/adult/adult.data does not exist: '/Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/datasets/../data/raw/adult/adult.data'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-99d14b2123a2>\", line 18, in <module>\n",
      "    data_set = load_preproc_data_adult(sub_samp=1000, balance=True)\n",
      "  File \"/Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/algorithms/preprocessing/optim_preproc_helpers/data_preproc_functions.py\", line 90, in load_preproc_data_adult\n",
      "    custom_preprocessing=custom_preprocessing)\n",
      "  File \"/Users/sethneel/Dropbox/Research/Current_Projects/AIF360/aif360/datasets/adult_dataset.py\", line 100, in __init__\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/sethneel/anaconda2/envs/aif360/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ],
     "output_type": "stream"
    },
    {
     "ename": "SystemExit",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ],
     "evalue": "1",
     "output_type": "error"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from aif360.algorithms.inprocessing.gerryfair_classifier import *\n",
    "from aif360.algorithms.inprocessing.gerryfair.clean import *\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import *\n",
    "from aif360.algorithms.inprocessing.gerryfair.auditor import *\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import linear_model\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data set\n",
    "data_set = load_preproc_data_adult(sub_samp=1000, balance=True)\n",
    "max_iterations = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**instantiate, fit, and predict** \n",
    "\n",
    "\n",
    "We first demonstrate how to instantiate a `Model`, `train` it with respect to rich subgroup fairness, and `predict` the label of a new example. We remark that when we set the `print_flag = True` at each iteration of the algorithm we print the error, fairness violation, and violated group size of most recent model. The error is the classification error of the classifier. At each round the Learner tries to find a classifier that minimizes the classification error plus a weighted sum of the fairness disparities on all the groups that the Auditor has found up until that point. By contrast the Auditor tries to find the group at each round with the greatest rich subgroup disparity with respect to the Learner's model. We define `violated group size` as the size (as a fraction of the dataset size) of this group, and the `fairness violation` as the `violated group size` times the difference in the statistical rate (FP or FN rate) on the group vs. the whole population. \n",
    "\n",
    "In the example below we set `max_iterations=500` which is an order of magnitude less than the time to convergence observed in [the rich subgroup fairness empirical paper](https://arxiv.org/abs/1808.08166), but advise that this can be highly dataset dependent. Our target $\\gamma$-disparity is $\\gamma = .005$, our statistical rate is false positive rate or `FP`, and our cost-sensitive classification oracle is linear regression (more on that below). We observe that the unconstrained (with no fairness constraint) classifier has error $.235$ and $\\gamma$-disparity $.044$. After $500$ iterations we obtain a classifier that $\\gamma$-fair, and has error $.43$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "C = 100\n",
    "print_flag = True\n",
    "gamma = .005\n",
    "\n",
    "\n",
    "fair_model = GerryFairClassifier(C=C, printflag=print_flag, gamma=gamma, fairness_def='FP',\n",
    "             max_iters=max_iterations, heatmapflag=False)\n",
    "\n",
    "# fit method\n",
    "communities_all_errors, communities_violations = fair_model.fit(data_set,\n",
    "                                                 early_termination=True, return_values=True)\n",
    "\n",
    "# predict method. If threshold in (0, 1) produces binary predictions\n",
    "\n",
    "dataset_yhat = fair_model.predict(data_set, threshold=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-d heatmaps**\n",
    "\n",
    "We now show to generate a 3d-heatmap of unfairness using the `generate_heatmap` method. The $X-Y$ axes in the plot represent the coefficients of the linear threshold function that defines a protected subgroup with respect to the first two sensitive attributes. Which $2$ attributes are considered sensitive can be overwritten with the `col_index` argument. The $Z$-axes is the $\\gamma$-disparity (FP) of the corresponding subgroup defined by the linear threshold function. This is important because it allows us to (1) visualize convergence as the heatmap flattens and (2) brute force check the fairness in low-dimensions without relying on a heuristic auditor. See the [the rich subgroup fairness empirical paper](https://arxiv.org/abs/1808.08166) for a discussion of these plots. Note that in the below plot no group has a $\\gamma$-disparity of greater than $.005$, which we would expect since the set of linear threshold functions on two attributes is a subset of the set of linear threshold functions on all protected attributes, and the final model is $\\gamma$-fair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# output heatmap (brute force)\n",
    "# replace None with the relative path if you want to save the plot\n",
    "fair_model.heatmapflag = True\n",
    "fair_model.heatmap_path  = 'heatmap'\n",
    "fair_model.generate_heatmap(data_set, dataset_yhat.labels)\n",
    "Image(filename='{}.png'.format(fair_model.heatmap_path)) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**black-box auditing**\n",
    "\n",
    "We now show to audit any black box classifier with respect to rich subgroup fairness under either FP or FN rate. Note the below auditing procedure would work for any set of (soft) predictions $\\hat{y}$, and need make no assumptions about the structure of the predictor. We note that as expected the disparity of the group found is the same as the disparity printed out in the last iteration of the `fit` method.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# instantiate auditor\n",
    "auditor = Auditor(data_set, 'FP')\n",
    "\n",
    "y = array_to_tuple(data_set.labels)\n",
    "predictions = array_to_tuple(dataset_yhat.labels)\n",
    "\n",
    "# returns mean(predictions | y = 0) if 'FP' 1-mean(predictions | y = 1) if FN\n",
    "metric_baseline = auditor.get_baseline(y, predictions)\n",
    "\n",
    "# return the group with the largest disparity\n",
    "group = auditor.get_group(dataset_yhat.labels, metric_baseline)\n",
    "\n",
    "print('gamma disparity: {}'.format(group.weighted_disparity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pareto curves**\n",
    "\n",
    "The `FairFictPlay` algorithm implemented in the `fit` method converges given access to perfect oracles for solving cost-sensitive classification (CSC) problems. A cost-sensitive classification problem over a hypothesis class $\\mathcal{H}$ is $$\\min_{h}\\sum_{i = 1}^{n}(1-h(x_i))c_0 + h(x_i)c_1$$\n",
    "By default in this package, and in the companion [empirical](https://arxiv.org/abs/1808.08166) and [theory](https://arxiv.org/pdf/1711.05144.pdf) papers, the hypothesis class of the learner and the of the subgroups are hyperplanes. The corresponding heuristic oracle for solving the CSC problem first forms two regression problems $(x_i, c_0)$ and $(x_i, c_1)$. Then in the case of hyperplanes, trains two regressions $r_i: \\mathcal{X} \\to R$ which predict the costs of classifying a given point $x$ $0,1$ respectively. Finally the binary classifier output by the oracle is defined as $\\hat{r}(x) = \\arg\\min_{j \\in \\{0,1\\}}r_j(x)$. But of course if we are interesting in different hypothesis classes for the learner, we simply need different regressors. In this package in addition to linear regression, we've added support for regression trees, kernelized ridge regression, and support vector regression. Below we trace out Pareto curves of $\\gamma$-disparity vs. error for each of these different heuristic oracles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pareto_iters = 500\n",
    "def multiple_classifiers_pareto(dataset, gamma_list=[0.002, 0.005, 0.01, 0.02, 0.05, 0.1], save_results=False, iters=pareto_iters):\n",
    "\n",
    "    ln_predictor = linear_model.LinearRegression()\n",
    "    svm_predictor = svm.LinearSVR()\n",
    "    tree_predictor = tree.DecisionTreeRegressor(max_depth=3)\n",
    "    kernel_predictor = KernelRidge(alpha=1.0, gamma=1.0, kernel='rbf')\n",
    "    predictor_dict = {'Linear': {'predictor': ln_predictor, 'iters': iters},\n",
    "                      'SVR': {'predictor': svm_predictor, 'iters': iters},\n",
    "                      'Tree': {'predictor': tree_predictor, 'iters': iters},\n",
    "                      'Kernel': {'predictor': kernel_predictor, 'iters': iters}}\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    for pred in predictor_dict:\n",
    "        print('Curr Predictor: {}'.format(pred))\n",
    "        predictor = predictor_dict[pred]['predictor']\n",
    "        max_iters = predictor_dict[pred]['iters']\n",
    "        fair_clf = Model(C=100, printflag=True, gamma=1, predictor=predictor, max_iters=max_iters)\n",
    "        fair_clf.printflag = False\n",
    "        fair_clf.set_options(max_iters=max_iters)\n",
    "        errors, fp_violations, fn_violations = fair_clf.pareto(dataset, gamma_list)\n",
    "        results_dict[pred] = {'errors': errors, 'fp_violations': fp_violations, 'fn_violations': fn_violations}\n",
    "        plt.plot(errors, fp_violations, label=pred)\n",
    "\n",
    "    if save_results:\n",
    "        pickle.dump(results_dict, open('results_dict_' + str(gamma_list) + '_gammas' + str(gamma_list) + '.pkl', 'wb'))\n",
    "\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Unfairness')\n",
    "    plt.legend()\n",
    "    plt.title('Error vs. Unfairness\\n(Communities & Crime Dataset)')\n",
    "    plt.savefig('gerryfair_pareto.png')\n",
    "    plt.close()\n",
    "multiple_classifiers_pareto(data_set)\n",
    "Image(filename='gerryfair_pareto.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural question one might ask is, suppose we fix a statistical fairness definition for rich subgroup fairness like equality of false positive rates, `FP`. Does learning a classifier that is fair with respect to `FP` increase or decrease fairness with respect to false negative rates `FN`? One could see this relationship going in either direction - and indeed we submit that it is dataset dependent. In some cases, if enforcing `FP` fairness pushes the classifier towards the constant classifier, then it will also satisify `FN` rate fairness, since the constant classifier is perfectly fair (this appears to be the case below). However, if the hypothesis class is sufficiently rich, then one would expect that ceteris paribus since we are optimizing for error in addition to `FP` rate fairness, the algorithm would increase `FN` rate unfairness in order to decrease error. Below we trace the FN vs. FP rate tradeoff across a range of input $\\gamma$, where the classifier is optimized only for `FP` rate fairness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fp_vs_fn(dataset, gamma_list, iters):\n",
    "    fp_auditor = Auditor(dataset, 'FP')\n",
    "    fn_auditor = Auditor(dataset, 'FN')\n",
    "    fp_violations = []\n",
    "    fn_violations = []\n",
    "    for g in gamma_list:\n",
    "        print('gamma: {} '.format(g), end =\" \")\n",
    "        fair_model = GerryFairClassifier(C=100, printflag=False, gamma=g, max_iters=iters)\n",
    "        fair_model.set_options(gamma=g)\n",
    "        fair_model.fit(dataset)\n",
    "        predictions = (fair_model.predict(dataset)).labels\n",
    "        _, fp_diff = fp_auditor.audit(predictions)\n",
    "        _, fn_diff = fn_auditor.audit(predictions)\n",
    "        fp_violations.append(fp_diff)\n",
    "        fn_violations.append(fn_diff)\n",
    "\n",
    "    plt.plot(fp_violations, fn_violations, label='communities')\n",
    "    plt.xlabel('False Positive Disparity')\n",
    "    plt.ylabel('False Negative Disparity')\n",
    "    plt.legend()\n",
    "    plt.title('FP vs FN Unfairness')\n",
    "    plt.savefig('gerryfair_fp_fn.png')\n",
    "    plt.close()\n",
    "\n",
    "gamma_list = [0.001, 0.002, 0.003, 0.004, 0.005, 0.0075, 0.01, 0.02, 0.03, 0.05]\n",
    "fp_vs_fn(data_set, gamma_list, pareto_iters)\n",
    "Image(filename='gerryfair_fp_fn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}